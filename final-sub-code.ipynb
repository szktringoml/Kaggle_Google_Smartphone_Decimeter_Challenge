{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import library\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2, venn2_circles\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport pathlib\nimport plotly\nimport plotly.express as px\nfrom scipy.ndimage import gaussian_filter1d\nfrom scipy.interpolate import interp1d\nimport scipy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T00:47:17.516858Z","iopub.execute_input":"2021-11-15T00:47:17.517211Z","iopub.status.idle":"2021-11-15T00:47:17.522894Z","shell.execute_reply.started":"2021-11-15T00:47:17.517183Z","shell.execute_reply":"2021-11-15T00:47:17.522007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# utils","metadata":{}},{"cell_type":"code","source":"def calc_haversine(lat1, lon1, lat2, lon2):\n    RADIUS = 6_367_000\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat/2)**2 + \\\n        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    dist = 2 * RADIUS * np.arcsin(a**0.5)\n    return dist","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:17.807747Z","iopub.execute_input":"2021-11-15T00:47:17.808117Z","iopub.status.idle":"2021-11-15T00:47:17.814842Z","shell.execute_reply.started":"2021-11-15T00:47:17.808085Z","shell.execute_reply":"2021-11-15T00:47:17.81365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_trafic(df, center, zoom=9):\n    fig = px.scatter_mapbox(df,\n                            lat=\"latDeg\",\n                            lon=\"lngDeg\",\n                            color=\"phoneName\",\n                            labels=\"phoneName\",\n                            zoom=zoom,\n                            center=center,\n                            height=600,\n                            width=800)\n    fig.update_layout(mapbox_style='stamen-terrain')\n    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n    fig.update_layout(title_text=\"GPS trafic\")\n    fig.show()\n    \ndef visualize_collection(df, collection):\n    target_df = df[df['collectionName']==collection].copy()\n    lat_center = target_df['latDeg'].mean()\n    lng_center = target_df['lngDeg'].mean()\n    center = {\"lat\":lat_center, \"lon\":lng_center}\n    \n    visualize_trafic(target_df, center)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:17.947626Z","iopub.execute_input":"2021-11-15T00:47:17.948032Z","iopub.status.idle":"2021-11-15T00:47:17.956456Z","shell.execute_reply.started":"2021-11-15T00:47:17.947987Z","shell.execute_reply":"2021-11-15T00:47:17.955477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"apply gauss","metadata":{}},{"cell_type":"code","source":"#ガウシアンフィルターでlat,lngを平滑化\ndef apply_gauss_smoothing(df, params):\n    SZ_1 = params['sz_1']\n    SZ_2 = params['sz_2']\n    SZ_CRIT = params['sz_crit'] \n    \n    print(np.sqrt(SZ_1))\n    print(np.sqrt(SZ_2))\n\n    \n    #collectionとphoneのユニークな組み合わせを2次元配列で取得\n    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n    \n    for collection, phone in unique_paths:\n        #取得したいデータを取り出すためのbool値の配列を得る\n        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n        #unique_pathごとのlat,lngをnumpy配列として取り出す\n        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n        gaussian_filter1d(input=lat or lng,sigma(sqrt(0.85) or sqrt(5.65)))\n        \n        #data[:,0]は、全ての行のlatを1次元配列で取り出せる。つまり、時間の経過によるlat値の変化\n        lat_g1 = gaussian_filter1d(data[:, 0], np.sqrt(SZ_1))\n        lon_g1 = gaussian_filter1d(data[:, 1], np.sqrt(SZ_1))\n        lat_g2 = gaussian_filter1d(data[:, 0], np.sqrt(SZ_2))\n        lon_g2 = gaussian_filter1d(data[:, 1], np.sqrt(SZ_2))\n        \n        lat_dif = data[1:,0] - data[:-1,0]\n        lon_dif = data[1:,1] - data[:-1,1]\n\n        lat_crit = np.append(np.abs(gaussian_filter1d(lat_dif, np.sqrt(SZ_CRIT)) / (1e-9 + gaussian_filter1d(np.abs(lat_dif), np.sqrt(SZ_CRIT)))),[0])\n        lon_crit = np.append(np.abs(gaussian_filter1d(lon_dif, np.sqrt(SZ_CRIT)) / (1e-9 + gaussian_filter1d(np.abs(lon_dif), np.sqrt(SZ_CRIT)))),[0])           \n            \n        df.loc[cond, 'latDeg'] = lat_g1 * lat_crit + lat_g2 * (1.0 - lat_crit)\n        df.loc[cond, 'lngDeg'] = lon_g1 * lon_crit + lon_g2 * (1.0 - lon_crit)    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:18.256995Z","iopub.execute_input":"2021-11-15T00:47:18.257698Z","iopub.status.idle":"2021-11-15T00:47:18.269856Z","shell.execute_reply.started":"2021-11-15T00:47:18.25766Z","shell.execute_reply":"2021-11-15T00:47:18.268722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#collectionが同じなのに端末によって位置が違うのはあり得ない。それがノイズなので、平均をとる\ndef mean_with_other_phones(df):\n    #重複のないcollenctionNameの文字列のnumpy配列を作成\n    collections_list = df[['collectionName']].drop_duplicates().to_numpy()\n    \n    for collection in collections_list:\n        #collectionに含まれるphoneのnumpy配列\n        phone_list = df[df['collectionName'].to_list() == collection][['phoneName']].drop_duplicates().to_numpy()\n\n        phone_data = {}\n        corrections = {}\n        for phone in phone_list:\n            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n            phone_data[phone[0]] = df[cond][['millisSinceGpsEpoch', 'latDeg', 'lngDeg']].to_numpy()\n\n        for current in phone_data:\n            correction = np.ones(phone_data[current].shape, dtype=np.float)\n            correction[:,1:] = phone_data[current][:,1:]\n    \n            for other in phone_data:\n                if other == current:\n                    continue\n\n                loc = interp1d(phone_data[other][:,0], \n                               phone_data[other][:,1:], \n                               axis=0, \n                               kind='linear', \n                               copy=False, \n                               bounds_error=None, \n                               fill_value='extrapolate', \n                               assume_sorted=True)\n                \n                start_idx = 0\n                stop_idx = 0\n                for idx, val in enumerate(phone_data[current][:,0]):\n                    if val < phone_data[other][0,0]:\n                        start_idx = idx\n                    if val < phone_data[other][-1,0]:\n                        stop_idx = idx\n\n                if stop_idx - start_idx > 0:\n                    correction[start_idx:stop_idx,0] += 1\n                    correction[start_idx:stop_idx,1:] += loc(phone_data[current][start_idx:stop_idx,0])                    \n\n            correction[:,1] /= correction[:,0]\n            correction[:,2] /= correction[:,0]\n            \n            corrections[current] = correction.copy()\n        \n        for phone in phone_list:\n            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n            \n            df.loc[cond, ['latDeg', 'lngDeg']] = corrections[phone[0]][:,1:]            \n            \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:18.54735Z","iopub.execute_input":"2021-11-15T00:47:18.547734Z","iopub.status.idle":"2021-11-15T00:47:18.563055Z","shell.execute_reply.started":"2021-11-15T00:47:18.547703Z","shell.execute_reply":"2021-11-15T00:47:18.56182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"reject outlier","metadata":{}},{"cell_type":"code","source":"#ラグ特徴を用いて移動距離データを追加\ndef add_distance_diff(df):\n    df['latDeg_prev'] = df['latDeg'].shift(1)\n    df['latDeg_next'] = df['latDeg'].shift(-1)\n    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n    df['phone_prev'] = df['phone'].shift(1)\n    df['phone_next'] = df['phone'].shift(-1)\n    \n    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n    \n    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:18.863555Z","iopub.execute_input":"2021-11-15T00:47:18.864039Z","iopub.status.idle":"2021-11-15T00:47:18.873056Z","shell.execute_reply.started":"2021-11-15T00:47:18.864007Z","shell.execute_reply":"2021-11-15T00:47:18.871979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"phone mean","metadata":{}},{"cell_type":"code","source":"def make_lerp_data(df):\n    '''\n    Generate interpolated lat,lng values for different phone times in the same collection.\n    '''\n    org_columns = df.columns\n    \n    # Generate a combination of time x collection x phone and combine it with the original data (generate records to be interpolated)\n    time_list = df[['collectionName', 'millisSinceGpsEpoch']].drop_duplicates()\n    phone_list =df[['collectionName', 'phoneName']].drop_duplicates()\n    tmp = time_list.merge(phone_list, on='collectionName', how='outer')\n    \n    lerp_df = tmp.merge(df, on=['collectionName', 'millisSinceGpsEpoch', 'phoneName'], how='left')\n    lerp_df['phone'] = lerp_df['collectionName'] + '_' + lerp_df['phoneName']\n    lerp_df = lerp_df.sort_values(['phone', 'millisSinceGpsEpoch'])\n    \n    # linear interpolation\n    lerp_df['latDeg_prev'] = lerp_df['latDeg'].shift(1)\n    lerp_df['latDeg_next'] = lerp_df['latDeg'].shift(-1)\n    lerp_df['lngDeg_prev'] = lerp_df['lngDeg'].shift(1)\n    lerp_df['lngDeg_next'] = lerp_df['lngDeg'].shift(-1)\n    lerp_df['phone_prev'] = lerp_df['phone'].shift(1)\n    lerp_df['phone_next'] = lerp_df['phone'].shift(-1)\n    lerp_df['time_prev'] = lerp_df['millisSinceGpsEpoch'].shift(1)\n    lerp_df['time_next'] = lerp_df['millisSinceGpsEpoch'].shift(-1)\n    # Leave only records to be interpolated\n    lerp_df = lerp_df[(lerp_df['latDeg'].isnull())&(lerp_df['phone']==lerp_df['phone_prev'])&(lerp_df['phone']==lerp_df['phone_next'])].copy()\n    # calc lerp\n    lerp_df['latDeg'] = lerp_df['latDeg_prev'] + ((lerp_df['latDeg_next'] - lerp_df['latDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n    lerp_df['lngDeg'] = lerp_df['lngDeg_prev'] + ((lerp_df['lngDeg_next'] - lerp_df['lngDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n    \n    # Leave only the data that has a complete set of previous and next data.\n    lerp_df = lerp_df[~lerp_df['latDeg'].isnull()]\n    \n    return lerp_df[org_columns]\n\ndef calc_mean_pred(df, lerp_df):\n    '''\n    Make a prediction based on the average of the predictions of phones in the same collection.\n    '''\n    add_lerp = pd.concat([df, lerp_df])\n    mean_pred_result = add_lerp.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean().reset_index()\n    mean_pred_df = df[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].copy()\n    mean_pred_df = mean_pred_df.merge(mean_pred_result[['collectionName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['collectionName', 'millisSinceGpsEpoch'], how='left')\n    return mean_pred_df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:19.764398Z","iopub.execute_input":"2021-11-15T00:47:19.764795Z","iopub.status.idle":"2021-11-15T00:47:19.778861Z","shell.execute_reply.started":"2021-11-15T00:47:19.764762Z","shell.execute_reply":"2021-11-15T00:47:19.778115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#評価\ndef percentile50(x):\n    return np.percentile(x, 50)\ndef percentile95(x):\n    return np.percentile(x, 95)\ndef get_train_score(df, gt):\n    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n    # calc_distance_error\n    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n    # calc_evaluate_score\n    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n    res = df.groupby('phone')['err'].agg([percentile50, percentile95])\n    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n    score = res['p50_p90_mean'].mean()\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:19.967075Z","iopub.execute_input":"2021-11-15T00:47:19.967701Z","iopub.status.idle":"2021-11-15T00:47:19.975226Z","shell.execute_reply.started":"2021-11-15T00:47:19.967652Z","shell.execute_reply":"2021-11-15T00:47:19.974521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# data prep","metadata":{}},{"cell_type":"code","source":"# directory setting\nINPUT = '../input/google-smartphone-decimeter-challenge'","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:21.134001Z","iopub.execute_input":"2021-11-15T00:47:21.134627Z","iopub.status.idle":"2021-11-15T00:47:21.138098Z","shell.execute_reply.started":"2021-11-15T00:47:21.134592Z","shell.execute_reply":"2021-11-15T00:47:21.13714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\nbase_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\nsample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T01:11:29.760204Z","iopub.execute_input":"2021-11-15T01:11:29.760871Z","iopub.status.idle":"2021-11-15T01:11:30.177674Z","shell.execute_reply.started":"2021-11-15T01:11:29.760829Z","shell.execute_reply":"2021-11-15T01:11:30.176381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ground_truth\np = pathlib.Path(INPUT)\ngt_files = list(p.glob('train/*/*/ground_truth.csv'))\nprint('ground_truth.csv count : ', len(gt_files))\n\ngts = []\nfor gt_file in tqdm(gt_files):\n    gts.append(pd.read_csv(gt_file))\nground_truth = pd.concat(gts)\n\ndisplay(ground_truth.head())","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:21.815646Z","iopub.execute_input":"2021-11-15T00:47:21.81592Z","iopub.status.idle":"2021-11-15T00:47:22.450302Z","shell.execute_reply.started":"2021-11-15T00:47:21.815894Z","shell.execute_reply":"2021-11-15T00:47:22.449477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smoothed_baseline = apply_gauss_smoothing(base_train, {'sz_1' : 0.85, 'sz_2' : 5.65, 'sz_crit' : 1.5})","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:22.451766Z","iopub.execute_input":"2021-11-15T00:47:22.452045Z","iopub.status.idle":"2021-11-15T00:47:25.575602Z","shell.execute_reply.started":"2021-11-15T00:47:22.452017Z","shell.execute_reply":"2021-11-15T00:47:25.574711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_train = mean_with_other_phones(smoothed_baseline)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:47:25.576877Z","iopub.execute_input":"2021-11-15T00:47:25.577152Z","iopub.status.idle":"2021-11-15T00:47:38.05986Z","shell.execute_reply.started":"2021-11-15T00:47:25.577127Z","shell.execute_reply":"2021-11-15T00:47:38.058883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# reject outlier","metadata":{}},{"cell_type":"code","source":"# reject outlier\ntrain_ro = add_distance_diff(base_train)\nth = 50\ntrain_ro.loc[((train_ro['dist_prev'] > th) & (train_ro['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:48:01.944491Z","iopub.execute_input":"2021-11-15T00:48:01.944859Z","iopub.status.idle":"2021-11-15T00:48:02.075048Z","shell.execute_reply.started":"2021-11-15T00:48:01.944827Z","shell.execute_reply":"2021-11-15T00:48:02.073891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# kalman filter\nhttps://www.kaggle.com/emaerthin/demonstration-of-the-kalman-filter","metadata":{}},{"cell_type":"code","source":"!pip install simdkalman","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:48:03.426288Z","iopub.execute_input":"2021-11-15T00:48:03.426673Z","iopub.status.idle":"2021-11-15T00:48:09.997723Z","shell.execute_reply.started":"2021-11-15T00:48:03.426638Z","shell.execute_reply":"2021-11-15T00:48:09.996811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import simdkalman","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:48:09.999073Z","iopub.execute_input":"2021-11-15T00:48:09.999356Z","iopub.status.idle":"2021-11-15T00:48:10.003938Z","shell.execute_reply.started":"2021-11-15T00:48:09.999326Z","shell.execute_reply":"2021-11-15T00:48:10.002976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"T = 1.0\nstate_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\nprocess_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\nobservation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\nobservation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n\nkf = simdkalman.KalmanFilter(\n        state_transition = state_transition,\n        process_noise = process_noise,\n        observation_model = observation_model,\n        observation_noise = observation_noise)\n\ndef apply_kf_smoothing(df, kf_=kf):\n    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n    for collection, phone in unique_paths:\n        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n        data = data.reshape(1, len(data), 2)\n        smoothed = kf_.smooth(data)\n        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:48:10.005658Z","iopub.execute_input":"2021-11-15T00:48:10.005942Z","iopub.status.idle":"2021-11-15T00:48:10.021768Z","shell.execute_reply.started":"2021-11-15T00:48:10.005906Z","shell.execute_reply":"2021-11-15T00:48:10.020739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']\ntrain_ro_kf = apply_kf_smoothing(base_train[cols])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:48:10.025962Z","iopub.execute_input":"2021-11-15T00:48:10.026388Z","iopub.status.idle":"2021-11-15T00:48:59.682725Z","shell.execute_reply.started":"2021-11-15T00:48:10.026344Z","shell.execute_reply":"2021-11-15T00:48:59.681545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# phones mean prediction","metadata":{}},{"cell_type":"code","source":"train_ro_kf","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:48:59.688049Z","iopub.execute_input":"2021-11-15T00:48:59.690897Z","iopub.status.idle":"2021-11-15T00:48:59.725813Z","shell.execute_reply.started":"2021-11-15T00:48:59.688669Z","shell.execute_reply":"2021-11-15T00:48:59.724681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_lerp = make_lerp_data(train_ro_kf)\nprint(train_lerp)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:48:59.731293Z","iopub.execute_input":"2021-11-15T00:48:59.734236Z","iopub.status.idle":"2021-11-15T00:49:00.740825Z","shell.execute_reply.started":"2021-11-15T00:48:59.734173Z","shell.execute_reply":"2021-11-15T00:49:00.73977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mean_pred = calc_mean_pred(train_ro_kf, train_lerp)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:49:00.742005Z","iopub.execute_input":"2021-11-15T00:49:00.742328Z","iopub.status.idle":"2021-11-15T00:49:00.894394Z","shell.execute_reply.started":"2021-11-15T00:49:00.742296Z","shell.execute_reply":"2021-11-15T00:49:00.893499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mean_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:49:00.89716Z","iopub.execute_input":"2021-11-15T00:49:00.89759Z","iopub.status.idle":"2021-11-15T00:49:00.912837Z","shell.execute_reply.started":"2021-11-15T00:49:00.897546Z","shell.execute_reply":"2021-11-15T00:49:00.912106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"tmp1 = train_ro_kf.copy()\ntmp2 = train_mean_pred.copy()\ntmp2['phoneName'] = tmp2['phoneName'] + '_MEAN'\ntmp3 = ground_truth.copy()\ntmp3['phoneName'] = tmp3['phoneName'] + '_GT'\ntmp = pd.concat([tmp1, tmp2, tmp3])\nvisualize_collection(tmp, '2020-05-14-US-MTV-1')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:49:00.914168Z","iopub.execute_input":"2021-11-15T00:49:00.914449Z","iopub.status.idle":"2021-11-15T00:49:00.92711Z","shell.execute_reply.started":"2021-11-15T00:49:00.914422Z","shell.execute_reply":"2021-11-15T00:49:00.926079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mean_pred[\"phone\"] = train_mean_pred[\"collectionName\"]+\"_\"+[\"phoneName\"]","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:49:00.928249Z","iopub.execute_input":"2021-11-15T00:49:00.928553Z","iopub.status.idle":"2021-11-15T00:49:00.979498Z","shell.execute_reply.started":"2021-11-15T00:49:00.928526Z","shell.execute_reply":"2021-11-15T00:49:00.978522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Psition_shift","metadata":{}},{"cell_type":"code","source":"base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:49:00.980764Z","iopub.execute_input":"2021-11-15T00:49:00.98104Z","iopub.status.idle":"2021-11-15T00:49:01.169539Z","shell.execute_reply.started":"2021-11-15T00:49:00.981014Z","shell.execute_reply":"2021-11-15T00:49:01.168519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pyproj\nfrom pyproj import Proj, transform\n\ndef calc_haversine(lat1, lon1, lat2, lon2):\n    RADIUS = 6_367_000\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat/2)**2 + \\\n        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    dist = 2 * RADIUS * np.arcsin(a**0.5)\n    return dist\n\ndef compute_dist(fname, fname2 = 'gt.csv'):\n    oof = pd.read_csv(fname)\n    gt = pd.read_csv(fname2)\n    #fname(base_train)に対してphoneとtimeをキーとしてgtとマージさせる\n    #trainのカラムには_x、gtのカラムには_yがつく\n    df = oof.merge(gt, on = ['phone','millisSinceGpsEpoch'])\n    #ハバーシン式でtrainとgtの誤差の2点間の距離を計算\n    dst_oof = calc_haversine(df.latDeg_x,df.lngDeg_x, df.latDeg_y, df.lngDeg_y)\n    #scores=phoneとdstで成り立つdf\n    scores = pd.DataFrame({'phone': df.phone,'dst': dst_oof})\n    #phoneでgroup化\n    scores_grp = scores.groupby('phone')\n    #quantile(分位数) .50は中央値を出力\n    d50 = scores_grp.quantile(.50).reset_index()\n    d50.columns = ['phone','q50']\n    d95 = scores_grp.quantile(.95).reset_index()\n    d95.columns = ['phone','q95']\n    #各phoneの50,95パーセンタイル値の平均を足して2で割ったものと、d50とd95をマージしたものを出力\n    return (scores_grp.quantile(.50).mean() + scores_grp.quantile(.95).mean())/2, d50.merge(d95)\n\n#ECEFは、位置をX、Y、およびZ座標として表します。原点は地球の重心として定義。\ndef WGS84_to_ECEF(lat, lon, alt):\n    # convert to radians\n    rad_lat = lat * (np.pi / 180.0)\n    rad_lon = lon * (np.pi / 180.0)\n    a    = 6378137.0\n    # f is the flattening factor\n    finv = 298.257223563\n    f = 1 / finv   \n    # e is the eccentricity\n    e2 = 1 - (1 - f) * (1 - f)    \n    # N is the radius of curvature in the prime vertical\n    N = a / np.sqrt(1 - e2 * np.sin(rad_lat) * np.sin(rad_lat))\n    x = (N + alt) * np.cos(rad_lat) * np.cos(rad_lon)\n    y = (N + alt) * np.cos(rad_lat) * np.sin(rad_lon)\n    z = (N * (1 - e2) + alt)        * np.sin(rad_lat)\n    return x, y, z\n\ntransformer = pyproj.Transformer.from_crs(\n    {\"proj\":'geocent', \"ellps\":'WGS84', \"datum\":'WGS84'},\n    {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'},)\n\n#ECEFからWGS84に\ndef ECEF_to_WGS84(x,y,z):\n    lon, lat, alt = transformer.transform(x,y,z,radians=False)\n    return lon, lat, alt\n\nsub_columns = sample_sub.columns\nbase_train[sub_columns].to_csv('btrain.csv',index = False)\n#train_mean_pred[sub_columns].to_csv('train_mean_pred.csv',index = False)\nbase_test[sub_columns].to_csv('btest.csv',index = False)\n\nmsge = 'millisSinceGpsEpoch'\ngt = ground_truth\ngt['phone'] = gt['collectionName'] + '_' + gt['phoneName']\ngt[sub_columns].to_csv('gt.csv', index = False)\n#WGS84楕円体上の高さの特徴\ngt['heightAboveWgs84EllipsoidM'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:49:01.171166Z","iopub.execute_input":"2021-11-15T00:49:01.17158Z","iopub.status.idle":"2021-11-15T00:49:03.565597Z","shell.execute_reply.started":"2021-11-15T00:49:01.171536Z","shell.execute_reply":"2021-11-15T00:49:03.564671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, scores = compute_dist('btrain.csv','gt.csv')\nprint(score)\nscores","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:55:05.082591Z","iopub.execute_input":"2021-11-15T00:55:05.083Z","iopub.status.idle":"2021-11-15T00:55:05.515932Z","shell.execute_reply.started":"2021-11-15T00:55:05.082966Z","shell.execute_reply":"2021-11-15T00:55:05.514554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ハイパーパラメーターの最適化の為に作られたベイズ最適化package\nimport optuna\n\n#\ndef position_shift(fname,a):\n    \n    d = pd.read_csv(fname)\n    #WGS84楕円体の高さを中央値で統一\n    d['heightAboveWgs84EllipsoidM'] = 63.52\n    d['x'], d['y'], d['z'] = zip(*d.apply(lambda x: WGS84_to_ECEF(x.latDeg, x.lngDeg, x.heightAboveWgs84EllipsoidM), axis=1))\n\n    #a = -0.2\n    d.sort_values(['phone', msge], inplace=True)\n    for fi in ['x','y','z']:\n        d[[fi+'p']] = d[fi].shift().where(d['phone'].eq(d['phone'].shift()))\n        d[[fi+'diff']] = d[fi]-d[fi+'p']\n    #d[['yp']] = d['y'].shift().where(d['phone'].eq(d['phone'].shift()))\n    d[['dist']] = np.sqrt(d['xdiff']**2 + d['ydiff']**2+ d['zdiff']**2)\n    for fi in ['x','y','z']:\n        d[[fi+'new']] = d[fi+'p'] + d[fi+'diff']*(1-a/d['dist'])\n    lng, lat, alt = ECEF_to_WGS84(d['xnew'].values,d['ynew'].values,d['znew'].values)\n    \n    lng[np.isnan(lng)] = d.loc[np.isnan(lng),'lngDeg']\n    lat[np.isnan(lat)] = d.loc[np.isnan(lat),'latDeg']\n    d['latDeg'] = lat\n    d['lngDeg'] = lng\n    \n    d.sort_values(['phone',msge],inplace = True)\n    ffname = 'shifted_' + fname\n    d[sub_columns].to_csv(ffname, index = False)\n    return ffname \ndef objective(trial):\n    a = trial.suggest_uniform('a', -1, 1)\n    score, scores = compute_dist(position_shift('btrain.csv', a),'gt.csv')\n    return score\n\n#optuna.studeyインスタンスを作る\nstudy = optuna.create_study()\n#optimizeに関数を渡して30回実行する\nstudy.optimize(objective, n_trials=50)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T00:55:07.722931Z","iopub.execute_input":"2021-11-15T00:55:07.723593Z","iopub.status.idle":"2021-11-15T01:03:08.984638Z","shell.execute_reply.started":"2021-11-15T00:55:07.723538Z","shell.execute_reply":"2021-11-15T01:03:08.983532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-11-15T01:03:08.986001Z","iopub.execute_input":"2021-11-15T01:03:08.986283Z","iopub.status.idle":"2021-11-15T01:03:08.993294Z","shell.execute_reply.started":"2021-11-15T01:03:08.986257Z","shell.execute_reply":"2021-11-15T01:03:08.992328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# position_shiftのcsv化\ncsvに学習したパラメータを入れる","metadata":{}},{"cell_type":"code","source":"def phoneTo(df):\n    df[\"collectionName\"],df[\"phoneName\"]=base_train[\"collectionName\"],base_train[\"phoneName\"]\n    df=df.drop([\"phone\"],axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:35:37.552183Z","iopub.execute_input":"2021-10-09T04:35:37.552472Z","iopub.status.idle":"2021-10-09T04:35:37.560947Z","shell.execute_reply.started":"2021-10-09T04:35:37.552443Z","shell.execute_reply":"2021-10-09T04:35:37.559801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# evaluate train score","metadata":{}},{"cell_type":"code","source":"print('kf + reject_outlier : ', get_train_score(train_ro_kf, ground_truth))\nprint('+ phones_mean_pred : ', get_train_score(train_mean_pred, ground_truth))\nprint('+ phones_mean_pred + position_shift : ',get_train_score(stmp , ground_truth))","metadata":{"execution":{"iopub.status.busy":"2021-10-09T10:00:44.503198Z","iopub.execute_input":"2021-10-09T10:00:44.503704Z","iopub.status.idle":"2021-10-09T10:00:45.110346Z","shell.execute_reply.started":"2021-10-09T10:00:44.503655Z","shell.execute_reply":"2021-10-09T10:00:45.108494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_train.to_csv('base_train_Shift.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:38:30.31081Z","iopub.execute_input":"2021-10-09T04:38:30.311433Z","iopub.status.idle":"2021-10-09T04:38:31.438416Z","shell.execute_reply.started":"2021-10-09T04:38:30.311398Z","shell.execute_reply":"2021-10-09T04:38:31.437518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"position_shift('base_train_Shift.csv', a = study.best_params['a'])","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:38:43.627113Z","iopub.execute_input":"2021-10-09T04:38:43.627499Z","iopub.status.idle":"2021-10-09T04:38:52.814273Z","shell.execute_reply.started":"2021-10-09T04:38:43.627462Z","shell.execute_reply":"2021-10-09T04:38:52.813314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shifted_base = pd.read_csv(\"shifted_base_train_Shift.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:38:52.815709Z","iopub.execute_input":"2021-10-09T04:38:52.81601Z","iopub.status.idle":"2021-10-09T04:38:52.929855Z","shell.execute_reply.started":"2021-10-09T04:38:52.815981Z","shell.execute_reply":"2021-10-09T04:38:52.928806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#多分検証用\nsmoothed_baseline = apply_gauss_smoothing(base_train, {'sz_1' : 0.85, 'sz_2' : 5.65, 'sz_crit' : 1.5})\nbase_train = mean_with_other_phones(smoothed_baseline)\nbase_train[sub_columns].to_csv('smooth.csv',index = False)\nposition_shift('smooth.csv', a = study.best_params['a'])\nsmoothbase_train = pd.read_csv(\"./smooth.csv\")\nbase_train[\"latDeg\"],base_train[\"lngDeg\"] = shifted_base['latDeg'],shifted_base['lngDeg']\nbase_train = add_distance_diff(base_train)\nprint(len(base_train))\nth = 50\nbase_train.loc[((base_train['dist_prev'] > th) & (base_train['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\nprint(len(base_train))\ntrain_kf = apply_kf_smoothing(base_train)\ntrain_lerp = make_lerp_data(train_kf)\ntrain_mean_pred = calc_mean_pred(train_kf, train_lerp)\nprint(len(train_mean_pred))\n\n#sample_sub['latDeg'] = train_mean_pred['latDeg']\n#sample_sub['lngDeg'] = train_mean_pred['lngDeg']\n#sample_sub\ntrain_mean_pred[\"phone\"] = train_mean_pred[\"collectionName\"]+\"_\"+train_mean_pred[\"phoneName\"]\ntrain_mean_pred.to_csv('train_mean_pred.csv', index=False)\nposition_shift('train_mean_pred.csv', a = study.best_params['a'])\nstmp = pd.read_csv('./shifted_train_mean_pred.csv')\nstmp[\"collectionName\"],stmp[\"phoneName\"] = base_train[\"collectionName\"],base_train[\"phoneName\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-09T09:55:12.903164Z","iopub.execute_input":"2021-10-09T09:55:12.903739Z","iopub.status.idle":"2021-10-09T09:55:12.988512Z","shell.execute_reply.started":"2021-10-09T09:55:12.903631Z","shell.execute_reply":"2021-10-09T09:55:12.986804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#多分検証用\nsmoothed_baseline = apply_gauss_smoothing(base_train, {'sz_1' : 0.85, 'sz_2' : 5.65, 'sz_crit' : 1.5})\nbase_train = mean_with_other_phones(smoothed_baseline)\nbase_train[sub_columns].to_csv('smooth.csv',index = False)\nposition_shift('smooth.csv', a = study.best_params['a'])\nsmoothbase_train = pd.read_csv(\"./smooth.csv\")\nbase_train[\"latDeg\"],base_train[\"lngDeg\"] = shifted_base['latDeg'],shifted_base['lngDeg']\nbase_train = add_distance_diff(base_train)\nprint(len(base_train))\nth = 50\nbase_train.loc[((base_train['dist_prev'] > th) & (base_train['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\nprint(len(base_train))\ntrain_kf = apply_kf_smoothing(base_train)\ntrain_lerp = make_lerp_data(train_kf)\ntrain_mean_pred = calc_mean_pred(train_kf, train_lerp)\nprint(len(train_mean_pred))\n\n#sample_sub['latDeg'] = train_mean_pred['latDeg']\n#sample_sub['lngDeg'] = train_mean_pred['lngDeg']\n#sample_sub\ntrain_mean_pred[\"phone\"] = train_mean_pred[\"collectionName\"]+\"_\"+train_mean_pred[\"phoneName\"]\ntrain_mean_pred.to_csv('train_mean_pred.csv', index=False)\nposition_shift('train_mean_pred.csv', a = study.best_params['a'])\nstmp = pd.read_csv('./shifted_train_mean_pred.csv')\nstmp[\"collectionName\"],stmp[\"phoneName\"] = base_train[\"collectionName\"],base_train[\"phoneName\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-09T10:10:04.184927Z","iopub.execute_input":"2021-10-09T10:10:04.185289Z","iopub.status.idle":"2021-10-09T10:10:30.056766Z","shell.execute_reply.started":"2021-10-09T10:10:04.185256Z","shell.execute_reply":"2021-10-09T10:10:30.054929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make submission","metadata":{}},{"cell_type":"code","source":"#make submittion\nsample_sub['latDeg'] = base_test['latDeg']\nsample_sub['lngDeg'] = base_test['lngDeg']\nsmoothed_baseline = apply_gauss_smoothing(base_test, {'sz_1' : 0.85, 'sz_2' : 5.65, 'sz_crit' : 1.5})\nsample_sub['latDeg'] = smoothed_baseline['latDeg']\nsample_sub['lngDeg'] = smoothed_baseline['lngDeg']\nbase_test = mean_with_other_phones(smoothed_baseline)\nbase_test = add_distance_diff(base_test)\nth = 50\nbase_test.loc[((base_test['dist_prev'] > th) & (base_test['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\n\ntest_kf = apply_kf_smoothing(base_test)\ntest_lerp = make_lerp_data(base_kf)\ntest_mean_pred = calc_mean_pred(base_kf, test_lerp)\n\nsample_sub['latDeg'] = test_mean_pred['latDeg']\nsample_sub['lngDeg'] = test_mean_pred['lngDeg']\nsample_sub.to_csv('test_mean_pred_without_ol,kf.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T01:28:30.628788Z","iopub.execute_input":"2021-11-15T01:28:30.629165Z","iopub.status.idle":"2021-11-15T01:28:41.518443Z","shell.execute_reply.started":"2021-11-15T01:28:30.629134Z","shell.execute_reply":"2021-11-15T01:28:41.517376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub","metadata":{"execution":{"iopub.status.busy":"2021-11-15T01:27:55.303954Z","iopub.execute_input":"2021-11-15T01:27:55.304304Z","iopub.status.idle":"2021-11-15T01:27:55.320491Z","shell.execute_reply.started":"2021-11-15T01:27:55.304275Z","shell.execute_reply":"2021-11-15T01:27:55.319367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"position_shift('mean_with_other.csv', a = study.best_params['a'])\nposition_shift('test_mean_pred.csv', a = study.best_params['a'])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T01:03:08.994823Z","iopub.execute_input":"2021-11-15T01:03:08.995101Z","iopub.status.idle":"2021-11-15T01:03:21.589517Z","shell.execute_reply.started":"2021-11-15T01:03:08.995076Z","shell.execute_reply":"2021-11-15T01:03:21.588363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}